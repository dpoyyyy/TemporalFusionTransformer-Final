# -*- coding: utf-8 -*-
"""TFT-VOL2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JRu1J1V7zbAzbUQA9UmOQ1EH7RtSvu9-
"""

# -*- coding: utf-8 -*-
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional, Dict, Tuple

# ======================================================================================
#  Part 1: Helper Functions (Sparsemax, GLU)
# ======================================================================================

def sparsemax(input: torch.Tensor, dim: int = -1) -> torch.Tensor:
    """
    A full and safe implementation of the Sparsemax activation function.

    Sparsemax projects the input onto the probability simplex, but unlike softmax,
    it can produce sparse outputs (i.e., with exact zeros).

    Args:
        input (torch.Tensor): The input tensor.
        dim (int): The dimension along which to apply Sparsemax.

    Returns:
        torch.Tensor: The tensor with Sparsemax applied.
    """
    if input.dim() == 0:
        return input

    # Transpose for easier processing along the last dimension
    input_t = input.transpose(dim, -1)

    # Sort input tensor in descending order
    zs = torch.sort(input_t, dim=-1, descending=True)[0]

    # Determine the number of non-zero probabilities
    k_range = torch.arange(1, zs.size(-1) + 1, device=zs.device, dtype=zs.dtype)
    view_shape = [1] * (zs.dim() - 1) + [zs.size(-1)]
    k_tensor = k_range.view(view_shape)

    bound = 1 + k_tensor * zs
    cumsum_zs = torch.cumsum(zs, dim=-1)
    is_gt = (bound > cumsum_zs).to(zs.dtype)
    k = torch.sum(is_gt, dim=-1, keepdim=True)

    # Ensure k is at least 1 to avoid division by zero
    k_safe = torch.clamp(k, min=1.0)

    # Calculate the threshold tau
    zs_sparse = zs * is_gt
    tau = (torch.sum(zs_sparse, dim=-1, keepdim=True) - 1) / k_safe

    # Apply the thresholding operation
    output = torch.clamp(input_t - tau, min=0.0)

    # Transpose back to the original dimension order
    return output.transpose(dim, -1)

class GLUUnit(nn.Module):
    """Gated Linear Unit helper module."""
    def __init__(self, in_features: int, out_features: int):
        super().__init__()
        self.linear = nn.Linear(in_features, out_features * 2)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Applies the Gated Linear Unit function.

        Args:
            x (torch.Tensor): Input tensor.

        Returns:
            torch.Tensor: Output of the GLU.
        """
        # The linear layer outputs two parts, which are then multiplied element-wise.
        # One part is passed through a sigmoid to act as a "gate".
        a, b = self.linear(x).chunk(2, dim=-1)
        return a * torch.sigmoid(b)

# ======================================================================================
#  Part 2: Core TFT Modules
# ======================================================================================

class GRN(nn.Module):
    """
    Gated Residual Network (GRN).

    This is a core building block of the Temporal Fusion Transformer, designed to
    create a flexible and non-linear processing layer. It includes a residual
    connection, feature transformation, an ELU activation, and a Gated Linear Unit (GLU)
    for controlled information flow. An optional context vector can be incorporated.

    Args:
        d_input (int): Input dimensionality.
        d_model (int): Internal and output dimensionality.
        d_context (Optional[int]): Dimensionality of the optional context vector.
        dropout_rate (float): Dropout rate.
    """
    def __init__(self, d_input: int, d_model: int, d_context: Optional[int] = None, dropout_rate: float = 0.1):
        super().__init__()
        self.linear_a = nn.Linear(d_input, d_model)
        self.linear_c = nn.Linear(d_context, d_model, bias=False) if d_context is not None else None
        self.activation = nn.ELU()
        self.dropout = nn.Dropout(dropout_rate)
        self.glu = GLUUnit(d_model, d_model)
        # Projection for the residual connection if input and output dimensions differ
        self.proj_skip = nn.Linear(d_input, d_model) if d_input != d_model else None
        self.layer_norm = nn.LayerNorm(d_model)
        self._init_weights()

    def _init_weights(self):
        """Initializes weights using Xavier uniform distribution."""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None: nn.init.zeros_(m.bias)
            elif isinstance(m, nn.LayerNorm):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)

    def forward(self, a: torch.Tensor, c: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        Forward pass for the GRN.

        Args:
            a (torch.Tensor): The primary input tensor.
            c (Optional[torch.Tensor]): The optional context tensor.

        Returns:
            torch.Tensor: The output tensor of the same shape as the input `a` (after projection).
        """
        # Residual connection
        residual = self.proj_skip(a) if self.proj_skip is not None else a

        # Main path
        a_proj = self.linear_a(a)
        c_proj = self.linear_c(c) if (c is not None and self.linear_c is not None) else None

        # Add context if provided, expanding its dimensions to match the primary input if necessary
        if c_proj is not None and c_proj.dim() == 2 and a_proj.dim() == 3:
            c_proj = c_proj.unsqueeze(1).expand(-1, a_proj.shape[1], -1)

        combined = a_proj + (c_proj if c_proj is not None else 0)
        activated = self.activation(combined)
        dropped_out = self.dropout(activated)
        gated = self.glu(dropped_out)

        # Add residual and apply layer normalization
        return self.layer_norm(residual + gated)

class VariableSelectionNetwork(nn.Module):
    """
    Variable Selection Network (VSN).

    This network learns to select the most relevant input variables at each time step.
    It takes a dictionary of raw input variables (both categorical and continuous)
    and produces a single feature vector representing the weighted combination of these variables.

    Args:
        d_model (int): The embedding and output dimensionality.
        input_dims (Dict[str, int]): Dictionary mapping variable names to their input dimension.
                                     For categorical variables, this is the number of categories.
                                     For continuous variables, this is the feature dimension (usually 1).
        var_types (Dict[str, str]): Dictionary mapping variable names to their type ('categorical' or 'continuous').
        is_time_varying (bool): Flag indicating if the inputs are time-varying.
        context_dim (Optional[int]): Dimensionality of an optional context vector for the GRNs.
        selection_method (str): Method for calculating weights ('softmax' or 'sparsemax').
    """
    def __init__(self, d_model: int, input_dims: Dict[str, int], var_types: Dict[str, str], is_time_varying: bool, context_dim: Optional[int] = None, selection_method: str = 'softmax'):
        super().__init__()
        self.is_time_varying = is_time_varying
        self.variable_names = list(input_dims.keys())
        self.num_vars = len(self.variable_names)
        self.d_model = d_model
        self.var_types = var_types
        self.selection_method = selection_method

        # Create specific input layers for each variable type
        self.input_converters = nn.ModuleDict()
        for name, dim in input_dims.items():
            v_type = self.var_types.get(name, 'continuous')
            if v_type == 'categorical':
                self.input_converters[name] = nn.Embedding(dim, d_model)
            else:
                self.input_converters[name] = nn.Linear(dim, d_model)

        # A GRN for each variable to process its embedding
        self.variable_grns = nn.ModuleDict({name: GRN(d_model, d_model, d_context=context_dim) for name in self.variable_names})

        # A master GRN to calculate variable importance scores
        self.scoring_grn = GRN(self.num_vars * d_model, max(d_model, 32), d_context=context_dim)
        self.score_projection = nn.Linear(max(d_model, 32), self.num_vars)
        self._init_weights()

    def _init_weights(self):
        """Initializes weights using Xavier uniform distribution."""
        for m in self.modules():
            if isinstance(m, (nn.Linear, nn.Embedding)):
                if hasattr(m, 'weight'): nn.init.xavier_uniform_(m.weight)
                if hasattr(m, 'bias') and m.bias is not None: nn.init.zeros_(m.bias)

    def forward(self, variables: Dict[str, torch.Tensor], context: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Forward pass for the VSN.

        Args:
            variables (Dict[str, torch.Tensor]): A dictionary of input tensors, one for each variable.
            context (Optional[torch.Tensor]): An optional context vector.

        Returns:
            Tuple[torch.Tensor, torch.Tensor]:
                - combined (torch.Tensor): The final feature vector after variable selection.
                - weights (torch.Tensor): The learned importance weights for each variable.
        """
        if self.is_time_varying: T = next(iter(variables.values())).shape[1]

        raw_embs, processed = [], []
        for name in self.variable_names:
            v = variables[name]
            v_type = self.var_types.get(name, 'continuous')

            # 1. Convert each raw input to a d_model embedding
            emb = self.input_converters[name](v.long() if v_type == 'categorical' else v)

            # 2. Ensure consistent dimensions for time-varying and static inputs
            if self.is_time_varying:
                if emb.dim() == 2: emb = emb.unsqueeze(1).expand(-1, T, -1)
            else:
                if emb.dim() == 3: emb = emb.mean(dim=1) # Aggregate time-varying to static if needed

            raw_embs.append(emb)
            # 3. Process each variable's embedding through its own GRN
            processed.append(self.variable_grns[name](emb, context))

        # 4. Create a single flat vector of all raw embeddings to score them
        flattened = torch.cat(raw_embs, dim=-1)

        # 5. Calculate variable scores using a shared GRN
        score_hidden = self.scoring_grn(flattened, context)
        scores = self.score_projection(score_hidden)

        # 6. Convert scores to weights using softmax or sparsemax
        weights = sparsemax(scores, dim=-1) if self.selection_method == 'sparsemax' else F.softmax(scores, dim=-1)

        # 7. Combine the GRN-processed variables using the learned weights
        stacked = torch.stack(processed, dim=-2)
        # Einstein summation for weighted sum: (batch, time, num_vars, d_model) * (batch, time, num_vars) -> (batch, time, d_model)
        combined = torch.einsum('...vd,...v->...d', stacked, weights)

        return combined, weights

class StaticCovariateEncoder(nn.Module):
    """
    Static Covariate Encoder (SCE).

    This module encodes the single feature vector from the static VSN into four
    distinct context vectors, each tailored for a different purpose within the TFT model:
    - c_s: For variable selection in time-varying VSNs.
    - c_c: For initializing the decoder's hidden state (cell state).
    - c_h: For initializing the decoder's hidden state (hidden state).
    - c_e: For enriching the temporal features.

    Args:
        d_model (int): The dimensionality of the input and output context vectors.
        dropout_rate (float): Dropout rate for the GRNs.
    """
    def __init__(self, d_model: int, dropout_rate: float = 0.1):
        super().__init__()
        self.context_encoders = nn.ModuleDict({
            n: GRN(d_model, d_model, dropout_rate=dropout_rate) for n in ['c_s', 'c_c', 'c_h', 'c_e']
        })

    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        Generates context vectors from the static feature vector.

        Args:
            x (torch.Tensor): The output of the static VariableSelectionNetwork.

        Returns:
            Dict[str, torch.Tensor]: A dictionary of context vectors.
        """
        return {n: enc(x) for n, enc in self.context_encoders.items()}

class Seq2SeqLSTM(nn.Module):
    """
    Sequence-to-sequence layer for local processing using LSTMs.

    This module uses an encoder-decoder LSTM structure to capture local temporal patterns.
    The encoder processes past inputs, and its final hidden state is used to initialize
    the decoder, which processes future (known) inputs.

    Args:
        d_model (int): Input feature dimensionality.
        hidden (int): LSTM hidden state dimensionality.
        num_layers (int): Number of LSTM layers.
        bidirectional (bool): If True, use a bidirectional encoder.
        dropout_rate (float): Dropout rate between LSTM layers (if num_layers > 1).
    """
    def __init__(self, d_model: int, hidden: int, num_layers: int = 1, bidirectional: bool = False, dropout_rate: float = 0.0):
        super().__init__()
        self.encoder = nn.LSTM(d_model, hidden, num_layers=num_layers, batch_first=True, bidirectional=bidirectional, dropout=dropout_rate if num_layers > 1 else 0.0)
        self.decoder = nn.LSTM(d_model, hidden, num_layers=num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0.0)

        # Layers to project static contexts into initial LSTM states
        self.init_h_proj = nn.Linear(d_model, num_layers * hidden * (2 if bidirectional else 1))
        self.init_c_proj = nn.Linear(d_model, num_layers * hidden * (2 if bidirectional else 1))

        self.bidirectional = bidirectional
        self.num_layers = num_layers
        self.hidden = hidden

        # If the encoder is bidirectional, we need to combine the forward and backward states
        if self.bidirectional:
            self.h_comb_proj = nn.Linear(2 * hidden, hidden)
            self.c_comb_proj = nn.Linear(2 * hidden, hidden)
        self._init_weights()

    def _init_weights(self):
        """Initializes weights using Xavier uniform distribution."""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None: nn.init.zeros_(m.bias)

    def _project_states(self, c_h_in: torch.Tensor, c_c_in: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """Projects static contexts to the initial hidden and cell states for the LSTM."""
        B = c_h_in.shape[0]
        total_dims = self.num_layers * (2 if self.bidirectional else 1)
        h0 = self.init_h_proj(c_h_in).view(B, total_dims, self.hidden).permute(1, 0, 2).contiguous()
        c0 = self.init_c_proj(c_c_in).view(B, total_dims, self.hidden).permute(1, 0, 2).contiguous()
        return h0, c0

    def forward(self, hist: torch.Tensor, fut: torch.Tensor, c_h: torch.Tensor, c_c: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Forward pass for the Seq2Seq LSTM.

        Args:
            hist (torch.Tensor): Historical (encoder) input sequence.
            fut (torch.Tensor): Future (decoder) input sequence.
            c_h (torch.Tensor): Static context for the initial hidden state.
            c_c (torch.Tensor): Static context for the initial cell state.

        Returns:
            Tuple[torch.Tensor, torch.Tensor]:
                - enc_out (torch.Tensor): Encoder output sequence.
                - dec_out (torch.Tensor): Decoder output sequence.
        """
        B = hist.shape[0]

        # Get initial states for the encoder from static contexts
        h0_enc, c0_enc = self._project_states(c_h, c_c)

        # Process historical sequence with the encoder
        enc_out, (h_n, c_n) = self.encoder(hist, (h0_enc, c0_enc))

        # Prepare decoder initial states from the encoder's final states
        if self.bidirectional:
            # Reshape and combine bidirectional states
            h_n = h_n.view(self.num_layers, 2, B, self.hidden).permute(0, 2, 1, 3).reshape(self.num_layers, B, 2 * self.hidden)
            c_n = c_n.view(self.num_layers, 2, B, self.hidden).permute(0, 2, 1, 3).reshape(self.num_layers, B, 2 * self.hidden)
            h_dec_init, c_dec_init = self.h_comb_proj(h_n), self.c_comb_proj(c_n)
        else:
            h_dec_init, c_dec_init = h_n, c_n

        # Process future sequence with the decoder
        dec_out, _ = self.decoder(fut, (h_dec_init, c_dec_init))

        return enc_out, dec_out

class InterpretableMultiHeadAttention(nn.Module):
    """
    Interpretable Multi-Head Attention mechanism.

    This is a variant of multi-head attention designed for interpretability.
    Instead of concatenating the outputs of each head, it averages the attention
    weights across all heads. This averaged attention map is then applied to a
    single, shared value projection. This yields a single, easily interpretable
    attention pattern across the sequence.

    Args:
        d_model (int): Input and output dimensionality.
        n_heads (int): Number of attention heads.
        dropout_rate (float): Dropout rate for attention weights.
    """
    def __init__(self, d_model: int, n_heads: int = 4, dropout_rate: float = 0.1):
        super().__init__()
        self.n_heads = n_heads
        self.head_dim = d_model // n_heads
        self.q_proj = nn.Linear(d_model, d_model)
        self.k_proj = nn.Linear(d_model, d_model)
        self.v_proj = nn.Linear(d_model, d_model) # Shared value projection
        self.out_proj = nn.Linear(d_model, d_model)
        self.dropout = nn.Dropout(dropout_rate)
        self._init_weights()

    def _init_weights(self):
        """Initializes weights using Xavier uniform distribution."""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                 if hasattr(m, 'weight'): nn.init.xavier_uniform_(m.weight)
                 if hasattr(m, 'bias') and m.bias is not None: nn.init.zeros_(m.bias)

    def forward(self, x: torch.Tensor, mask: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Forward pass for interpretable attention.

        Args:
            x (torch.Tensor): The input sequence of shape (B, T, D).
            mask (Optional[torch.Tensor]): A causal mask to prevent attending to future positions.

        Returns:
            Tuple[torch.Tensor, torch.Tensor]:
                - out (torch.Tensor): The output sequence.
                - alpha_agg (torch.Tensor): The aggregated, interpretable attention weights.
        """
        B, T, _ = x.shape

        # Project and reshape Q, K into multiple heads
        Q = self.q_proj(x).view(B, T, self.n_heads, self.head_dim).permute(0, 2, 1, 3)
        K = self.k_proj(x).view(B, T, self.n_heads, self.head_dim).permute(0, 2, 1, 3)

        # Create a single, shared value projection
        V_shared = self.v_proj(x)

        # Calculate scaled dot-product attention scores for each head
        scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_dim ** 0.5)

        # Apply causal mask if provided
        if mask is not None:
            mask_expanded = mask.unsqueeze(0).unsqueeze(0)
            scores = scores.masked_fill(mask_expanded, float('-1e9'))

        attn_per_head = F.softmax(scores, dim=-1)
        attn_per_head = self.dropout(attn_per_head)

        # Key step: average attention weights across heads for interpretability
        alpha_agg = attn_per_head.mean(dim=1)

        # Apply the aggregated attention weights to the shared value projection
        # and project to the final output.
        out = self.out_proj(torch.matmul(alpha_agg, V_shared))

        return out, alpha_agg

class TemporalProcessor(nn.Module):
    """
    The complete temporal processing pipeline of the TFT.

    This module orchestrates the flow of information through the temporal layers:
    1. Local processing with a Seq2Seq LSTM.
    2. Gating and residual connection with the original input.
    3. Static enrichment by incorporating a static context vector.
    4. Interpretable multi-head self-attention to capture long-range dependencies.
    5. Gating and another residual connection.
    6. A final feed-forward GRN layer.
    7. A final gating and residual connection.

    Args:
        d_model (int): Main dimensionality of the temporal features.
        hidden (int): Hidden dimensionality for the LSTM layer.
        num_layers (int): Number of LSTM layers.
        n_heads (int): Number of attention heads.
        dropout_rate (float): General dropout rate for the sub-modules.
        bidirectional_encoder (bool): Whether the LSTM encoder should be bidirectional.
    """
    def __init__(self, d_model: int, hidden: int, num_layers: int = 1, n_heads: int = 4, dropout_rate: float = 0.1, bidirectional_encoder: bool = False):
        super().__init__()
        self.seq2seq = Seq2SeqLSTM(d_model, hidden, num_layers=num_layers, bidirectional=bidirectional_encoder, dropout_rate=dropout_rate)

        # If the encoder is bidirectional, the LSTM output dimension is doubled
        lstm_out_dim = hidden * (2 if bidirectional_encoder else 1)
        self.lstm_gate_and_norm = nn.Sequential(GLUUnit(lstm_out_dim, d_model), nn.LayerNorm(d_model))

        self.static_enrich = GRN(d_model, d_model, d_context=d_model, dropout_rate=dropout_rate)
        self.attention = InterpretableMultiHeadAttention(d_model, n_heads=n_heads, dropout_rate=dropout_rate)
        self.attention_gate = GRN(d_model, d_model, dropout_rate=dropout_rate)
        self.ffn_grn = GRN(d_model, d_model, dropout_rate=dropout_rate)

        # The final GRN has a unique structure where its context is the output of another layer
        self.final_gate = GRN(d_model, d_model, d_context=d_model, dropout_rate=dropout_rate)
        self._init_weights()

    def _init_weights(self):
        """Initializes weights using Xavier uniform distribution."""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None: nn.init.zeros_(m.bias)
            elif isinstance(m, nn.LayerNorm):
                nn.init.ones_(m.weight)
                if m.bias is not None: nn.init.zeros_(m.bias)

    def forward(self, hist_emb: torch.Tensor, fut_emb: torch.Tensor, contexts: Dict[str, torch.Tensor], causal_mask: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Forward pass for the temporal processor.

        Args:
            hist_emb (torch.Tensor): Feature embeddings for past time steps.
            fut_emb (torch.Tensor): Feature embeddings for future time steps.
            contexts (Dict[str, torch.Tensor]): Dictionary of static context vectors.
            causal_mask (Optional[torch.Tensor]): Causal mask for the self-attention layer.

        Returns:
            Tuple[torch.Tensor, torch.Tensor]:
                - final_out (torch.Tensor): The processed temporal features.
                - alpha (torch.Tensor): The interpretable attention weights.
        """
        # 1. Local Processing with LSTM
        enc_out, dec_out = self.seq2seq(hist_emb, fut_emb, contexts['c_h'], contexts['c_c'])
        lstm_output_seq = torch.cat([enc_out, dec_out], dim=1)

        # 2. Gating and Residual Connection for LSTM output
        gated_output = self.lstm_gate_and_norm(lstm_output_seq)
        lstm_input_seq = torch.cat([hist_emb, fut_emb], dim=1)
        processed_sequence = gated_output + lstm_input_seq

        # 3. Static Enrichment
        enriched = self.static_enrich(processed_sequence, c=contexts['c_e'])

        # 4. Interpretable Self-Attention
        attn_out, alpha = self.attention(enriched, mask=causal_mask)

        # 5. Gating and Residual for Attention output
        attn_gated = self.attention_gate(attn_out) + enriched

        # 6. Position-wise Feed-Forward GRN
        ffn_out = self.ffn_grn(attn_gated)

        # 7. Final Gating and Residual
        # Note: The output of the FFN acts as context for the final gate
        final_out = self.final_gate(ffn_out) + attn_gated

        return final_out, alpha

class TemporalFusionTransformer(nn.Module):
    """
    A complete and integrated Temporal Fusion Transformer (TFT) model.

    This model is designed for multi-horizon time series forecasting. It leverages
    static covariates, known future inputs, and historical time-series data to
    produce quantile forecasts.

    Key features include:
    - Gated Residual Networks (GRNs) for non-linear processing.
    - Variable Selection Networks (VSNs) for identifying salient features.
    - An encoder-decoder architecture for handling past and future inputs.
    - Interpretable multi-head attention for capturing long-range dependencies.

    Args:
        d_model (int): The main hidden dimensionality of the model.
        d_lstm_hidden (int): Hidden dimensionality of the LSTM layers.
        static_input_dims (Dict[str, int]): Dimensions for static variables.
        static_var_types (Dict[str, str]): Types for static variables ('categorical'/'continuous').
        past_input_dims (Dict[str, int]): Dimensions for historical variables.
        past_var_types (Dict[str, str]): Types for historical variables.
        future_input_dims (Dict[str, int]): Dimensions for known future variables.
        future_var_types (Dict[str, str]): Types for known future variables.
        num_lstm_layers (int): Number of layers in the LSTM.
        num_attn_heads (int): Number of heads in the attention mechanism.
        dropout_rate (float): General dropout rate.
        selection_method (str): Variable selection method ('softmax' or 'sparsemax').
        bidirectional_encoder (bool): Whether the LSTM encoder is bidirectional.
        num_quantiles (int): Number of output quantiles for the forecast.
    """
    def __init__(self, d_model: int, d_lstm_hidden: int, static_input_dims: Dict[str, int], static_var_types: Dict[str, str], past_input_dims: Dict[str, int], past_var_types: Dict[str, str], future_input_dims: Dict[str, int], future_var_types: Dict[str, str], num_lstm_layers: int = 1, num_attn_heads: int = 4, dropout_rate: float = 0.1, selection_method: str = 'softmax', bidirectional_encoder: bool = False, num_quantiles: int = 3):
        super().__init__()
        # Input processing layers
        self.static_vsn = VariableSelectionNetwork(d_model, static_input_dims, static_var_types, is_time_varying=False, selection_method=selection_method)
        self.past_vsn = VariableSelectionNetwork(d_model, past_input_dims, past_var_types, is_time_varying=True, context_dim=d_model, selection_method=selection_method)
        self.future_vsn = VariableSelectionNetwork(d_model, future_input_dims, future_var_types, is_time_varying=True, context_dim=d_model, selection_method=selection_method)

        # Static context generation
        self.static_encoder = StaticCovariateEncoder(d_model, dropout_rate)

        # Main temporal processing pipeline
        self.temporal_processor = TemporalProcessor(d_model, d_lstm_hidden, num_layers=num_lstm_layers, n_heads=num_attn_heads, dropout_rate=dropout_rate, bidirectional_encoder=bidirectional_encoder)

        # Final output layer to produce quantile forecasts
        self.output_projection = nn.Linear(d_model, num_quantiles)

    def forward(self, static_vars: Dict[str, torch.Tensor], past_vars: Dict[str, torch.Tensor], future_vars: Dict[str, torch.Tensor], return_interpretation: bool = False):
        """
        Full forward pass of the TFT model.

        Args:
            static_vars (Dict[str, torch.Tensor]): Dictionary of static input tensors.
            past_vars (Dict[str, torch.Tensor]): Dictionary of historical input tensors.
            future_vars (Dict[str, torch.Tensor]): Dictionary of known future input tensors.
            return_interpretation (bool): If True, returns a dictionary of interpretable weights.

        Returns:
            torch.Tensor or Tuple[torch.Tensor, Dict]:
                - predictions (torch.Tensor): The quantile forecasts.
                - interpretation (Dict): (Optional) A dictionary containing VSN and attention weights.
        """
        # 1. Process static variables to generate context vectors
        static_combined, static_weights = self.static_vsn(static_vars)
        contexts = self.static_encoder(static_combined)

        # 2. Process time-varying variables (past and future) using their respective VSNs
        past_emb, past_weights = self.past_vsn(past_vars, context=contexts['c_s'])
        future_emb, future_weights = self.future_vsn(future_vars, context=contexts['c_s'])

        # 3. Create a causal mask for the self-attention mechanism
        past_len = next(iter(past_vars.values())).shape[1]
        future_len = next(iter(future_vars.values())).shape[1]
        total_len = past_len + future_len
        # The mask ensures that a position can only attend to itself and previous positions
        causal_mask = torch.triu(torch.ones(total_len, total_len, device=past_emb.device), diagonal=1).bool()

        # 4. Run the main temporal processing pipeline
        temporal_output, attn_weights = self.temporal_processor(hist_emb=past_emb, fut_emb=future_emb, contexts=contexts, causal_mask=causal_mask)

        # 5. Select only the outputs corresponding to the future time steps for prediction
        prediction_input = temporal_output[:, past_len:, :]
        predictions = self.output_projection(prediction_input)

        if return_interpretation:
            interpretation = {
                "past_vsn_weights": past_weights,
                "future_vsn_weights": future_weights,
                "attention_weights": attn_weights,
                "static_vsn_weights": static_weights
            }
            return predictions, interpretation

        return predictions